{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f4acba8",
   "metadata": {},
   "source": [
    "# Question 1.\n",
    "1. **Difference between Simple and Multiple Linear Regression:**\n",
    "   - Simple Linear Regression uses one independent variable to predict a dependent variable, modeling the relationship as a straight line. Multiple Linear Regression, however, includes two or more independent variables, allowing for more complex relationships and providing a better fit to data that may be influenced by multiple factors.\n",
    "\n",
    "\n",
    "2. **Continuous vs. Indicator Variable in Simple Linear Regression:**\n",
    "   - A continuous variable represents numerical values with an infinite range, allowing for a linear trend. An indicator (or binary) variable, however, has two possible values (e.g., 0 or 1), effectively dividing data into two categories and shifting the regression line up or down based on category presence.\n",
    "\n",
    "\n",
    "3. **Behavior Change with an Indicator Variable in Multiple Linear Regression:**\n",
    "   - When an indicator variable is added alongside a continuous variable, the model can account for a “shift” in the line based on the category of the indicator variable. This means that different categories can have different baseline values, creating two parallel lines, each representing a category’s relationship with the continuous variable.\n",
    "\n",
    "\n",
    "4. **Effect of Adding an Interaction Between Continuous and Indicator Variable:**\n",
    "   - Adding an interaction term between a continuous and an indicator variable enables the model to fit different slopes for each category, allowing one category's influence to differ in intensity from the other. This non-parallel line behavior offers a more flexible fit when categories affect the continuous variable's impact differently.\n",
    "\n",
    "\n",
    "5. **Behavior of a Multiple Linear Regression with Indicator Variables from a Non-Binary Categorical Variable:**\n",
    "   - When using a non-binary categorical variable, the model creates a set of binary variables (often called “dummy” variables) to represent each category except one (the reference category). This setup allows the model to capture distinct shifts in the dependent variable for each category, making it adaptable for multi-category data by adjusting baselines based on the category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d3705",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "In this scenario, we have a company that sells sports equipment and wants to understand the impact of its advertising on **sales**. Here’s a breakdown of the **outcome and predictor variables**, the role of **interactions**, and how we could set up different models to make predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### Outcome and Predictor Variables\n",
    "\n",
    "- **Outcome Variable**: The outcome, or the variable we’re predicting, is **sales** or some measure of the effectiveness of the ads (e.g., customer engagement or revenue).\n",
    "  \n",
    "- **Predictor Variables**: The predictors are the **TV advertising budget** and **online advertising budget**. Both are initially treated as **continuous variables** representing the amount spent.\n",
    "\n",
    "- **Interaction**: Since the effectiveness of each ad type might depend on the budget of the other, there’s potential for an **interaction effect**. This means that the impact of one advertising budget on sales might change based on the other advertising budget, so the total effect isn’t simply additive.\n",
    "\n",
    "---\n",
    "\n",
    "### Linear Forms with and without Interaction\n",
    "\n",
    "1. **Without Interaction**:\n",
    "   - $\\text{Sales} = \\beta_0 + \\beta_1 \\times \\text{TV\\_Budget} + \\beta_2 \\times \\text{Online\\_Budget}$\n",
    "   - This formula assumes that TV and online budgets affect sales **independently**. Each predictor has a fixed contribution to sales regardless of the other.\n",
    "\n",
    "2. **With Interaction**:\n",
    "   - $\\text{Sales} = \\beta_0 + \\beta_1 \\times \\text{TV\\_Budget} + \\beta_2 \\times \\text{Online\\_Budget} + \\beta_3 \\times (\\text{TV\\_Budget} \\times \\text{Online\\_Budget})$\n",
    "   - Here, the interaction term $\\beta_3 \\times (\\text{TV\\_Budget} \\times \\text{Online\\_Budget})$ accounts for the combined influence of both ad budgets. This term allows the effect of one ad budget to change based on the level of the other, creating a more flexible model that may capture synergistic or diminishing returns in advertising.\n",
    "\n",
    "---\n",
    "\n",
    "### Making Predictions and Interpreting Differences\n",
    "\n",
    "1. **Without Interaction**:\n",
    "   - To predict sales, we plug in the values for TV and online budgets into the formula. Each dollar spent on TV and online advertising increases sales by a fixed amount, given by $\\beta_1$ and $\\beta_2$ respectively.\n",
    "   - **Difference in Predictions**: The model without interaction gives **independent effects**, meaning the budget for one type of ad has the same impact on sales no matter how much is spent on the other type.\n",
    "\n",
    "2. **With Interaction**:\n",
    "   - We use the same approach but include the interaction term. If both TV and online budgets are high, the interaction term may increase or decrease the effect on sales depending on whether they complement or detract from each other.\n",
    "   - **Difference in Predictions**: This model allows for **combined effects**, where each dollar spent on TV ads may have a larger or smaller effect on sales depending on the online ad budget (and vice versa). This could be useful if the effectiveness of one ad type enhances or limits the other.\n",
    "\n",
    "---\n",
    "\n",
    "### Binary (High/Low) Advertising Budgets\n",
    "\n",
    "If we categorize the TV and online budgets as **binary variables** representing “High” (1) and “Low” (0), the formulas would be adjusted as follows:\n",
    "\n",
    "1. **Without Interaction (Binary Predictors)**:\n",
    "   - $\\text{Sales} = \\beta_0 + \\beta_1 \\times \\text{TV\\_High} + \\beta_2 \\times \\text{Online\\_High}$\n",
    "   - Here, $\\text{TV\\_High}$ and $\\text{Online\\_High}$ are indicator variables (1 if high, 0 if low). This model estimates the **independent impact** of high spending on each ad type without an interaction effect.\n",
    "\n",
    "2. **With Interaction (Binary Predictors)**:\n",
    "   - $\\text{Sales} = \\beta_0 + \\beta_1 \\times \\text{TV\\_High} + \\beta_2 \\times \\text{Online\\_High} + \\beta_3 \\times (\\text{TV\\_High} \\times \\text{Online\\_High})$\n",
    "   - This version adds an interaction term, allowing the **joint high spending** on both ad types to impact sales differently than if only one or neither type had high spending.\n",
    "\n",
    "---\n",
    "\n",
    "### Making Predictions with Binary Models\n",
    "\n",
    "- **Without Interaction**: We can predict sales based on whether TV or online spending is high or low. This model doesn’t consider the joint effect, so it treats each ad type’s budget level as an independent contributor to sales.\n",
    "- **With Interaction**: By including the interaction term, this model adjusts sales predictions based on whether both ad budgets are high, both are low, or one is high and the other is low. It allows for a combined effect where high-high spending might have a unique impact on sales, differing from when only one budget is high. \n",
    "\n",
    "In summary, adding interaction terms in both continuous and binary cases allows for more nuanced predictions that reflect possible combined effects between the two types of ad spending.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147ed45",
   "metadata": {},
   "source": [
    "# Question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00fe8095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.228109\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>str8fyre</td>     <th>  No. Observations:  </th>  <td>   800</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   788</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 15 Nov 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.05156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>03:03:25</td>     <th>  Log-Likelihood:    </th> <td> -182.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -192.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.04757</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                      <td></td>                        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                <td>   -3.2644</td> <td>    0.714</td> <td>   -4.572</td> <td> 0.000</td> <td>   -4.664</td> <td>   -1.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                        <td>    4.3478</td> <td>    2.179</td> <td>    1.996</td> <td> 0.046</td> <td>    0.078</td> <td>    8.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 2\") == \"None\")[T.True]</th>         <td>    1.5432</td> <td>    0.853</td> <td>    1.810</td> <td> 0.070</td> <td>   -0.128</td> <td>    3.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>                       <td>   -0.0574</td> <td>    0.468</td> <td>   -0.123</td> <td> 0.902</td> <td>   -0.975</td> <td>    0.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>                       <td>   -0.6480</td> <td>    0.466</td> <td>   -1.390</td> <td> 0.164</td> <td>   -1.561</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>                       <td>   -0.8255</td> <td>    0.545</td> <td>   -1.516</td> <td> 0.130</td> <td>   -1.893</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>                       <td>   -0.5375</td> <td>    0.449</td> <td>   -1.198</td> <td> 0.231</td> <td>   -1.417</td> <td>    0.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>                       <td>    0.3213</td> <td>    0.477</td> <td>    0.673</td> <td> 0.501</td> <td>   -0.614</td> <td>    1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                   <td>    0.0172</td> <td>    0.006</td> <td>    3.086</td> <td> 0.002</td> <td>    0.006</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                 <td>   -0.0365</td> <td>    0.019</td> <td>   -1.884</td> <td> 0.060</td> <td>   -0.074</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                  <td>   -0.0098</td> <td>    0.008</td> <td>   -1.247</td> <td> 0.213</td> <td>   -0.025</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:I(Q(\"Type 2\") == \"None\")[T.True]</th> <td>   -0.0197</td> <td>    0.012</td> <td>   -1.651</td> <td> 0.099</td> <td>   -0.043</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                           &     str8fyre     & \\textbf{  No. Observations:  } &      800    \\\\\n",
       "\\textbf{Model:}                                   &      Logit       & \\textbf{  Df Residuals:      } &      788    \\\\\n",
       "\\textbf{Method:}                                  &       MLE        & \\textbf{  Df Model:          } &       11    \\\\\n",
       "\\textbf{Date:}                                    & Fri, 15 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &  0.05156    \\\\\n",
       "\\textbf{Time:}                                    &     03:03:25     & \\textbf{  Log-Likelihood:    } &   -182.49   \\\\\n",
       "\\textbf{converged:}                               &       True       & \\textbf{  LL-Null:           } &   -192.41   \\\\\n",
       "\\textbf{Covariance Type:}                         &    nonrobust     & \\textbf{  LLR p-value:       } &  0.04757    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                  & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                &      -3.2644  &        0.714     &    -4.572  &         0.000        &       -4.664    &       -1.865     \\\\\n",
       "\\textbf{Legendary[T.True]}                        &       4.3478  &        2.179     &     1.996  &         0.046        &        0.078    &        8.618     \\\\\n",
       "\\textbf{I(Q(\"Type 2\") == \"None\")[T.True]}         &       1.5432  &        0.853     &     1.810  &         0.070        &       -0.128    &        3.215     \\\\\n",
       "\\textbf{C(Generation)[T.2]}                       &      -0.0574  &        0.468     &    -0.123  &         0.902        &       -0.975    &        0.861     \\\\\n",
       "\\textbf{C(Generation)[T.3]}                       &      -0.6480  &        0.466     &    -1.390  &         0.164        &       -1.561    &        0.265     \\\\\n",
       "\\textbf{C(Generation)[T.4]}                       &      -0.8255  &        0.545     &    -1.516  &         0.130        &       -1.893    &        0.242     \\\\\n",
       "\\textbf{C(Generation)[T.5]}                       &      -0.5375  &        0.449     &    -1.198  &         0.231        &       -1.417    &        0.342     \\\\\n",
       "\\textbf{C(Generation)[T.6]}                       &       0.3213  &        0.477     &     0.673  &         0.501        &       -0.614    &        1.257     \\\\\n",
       "\\textbf{Attack}                                   &       0.0172  &        0.006     &     3.086  &         0.002        &        0.006    &        0.028     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                 &      -0.0365  &        0.019     &    -1.884  &         0.060        &       -0.074    &        0.001     \\\\\n",
       "\\textbf{Defense}                                  &      -0.0098  &        0.008     &    -1.247  &         0.213        &       -0.025    &        0.006     \\\\\n",
       "\\textbf{Defense:I(Q(\"Type 2\") == \"None\")[T.True]} &      -0.0197  &        0.012     &    -1.651  &         0.099        &       -0.043    &        0.004     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               str8fyre   No. Observations:                  800\n",
       "Model:                          Logit   Df Residuals:                      788\n",
       "Method:                           MLE   Df Model:                           11\n",
       "Date:                Fri, 15 Nov 2024   Pseudo R-squ.:                 0.05156\n",
       "Time:                        03:03:25   Log-Likelihood:                -182.49\n",
       "converged:                       True   LL-Null:                       -192.41\n",
       "Covariance Type:            nonrobust   LLR p-value:                   0.04757\n",
       "============================================================================================================\n",
       "                                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                   -3.2644      0.714     -4.572      0.000      -4.664      -1.865\n",
       "Legendary[T.True]                            4.3478      2.179      1.996      0.046       0.078       8.618\n",
       "I(Q(\"Type 2\") == \"None\")[T.True]             1.5432      0.853      1.810      0.070      -0.128       3.215\n",
       "C(Generation)[T.2]                          -0.0574      0.468     -0.123      0.902      -0.975       0.861\n",
       "C(Generation)[T.3]                          -0.6480      0.466     -1.390      0.164      -1.561       0.265\n",
       "C(Generation)[T.4]                          -0.8255      0.545     -1.516      0.130      -1.893       0.242\n",
       "C(Generation)[T.5]                          -0.5375      0.449     -1.198      0.231      -1.417       0.342\n",
       "C(Generation)[T.6]                           0.3213      0.477      0.673      0.501      -0.614       1.257\n",
       "Attack                                       0.0172      0.006      3.086      0.002       0.006       0.028\n",
       "Attack:Legendary[T.True]                    -0.0365      0.019     -1.884      0.060      -0.074       0.001\n",
       "Defense                                     -0.0098      0.008     -1.247      0.213      -0.025       0.006\n",
       "Defense:I(Q(\"Type 2\") == \"None\")[T.True]    -0.0197      0.012     -1.651      0.099      -0.043       0.004\n",
       "============================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's an example of how you can do this\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "pokeaman = pd.read_csv(url).fillna('None')\n",
    "\n",
    "pokeaman['str8fyre'] = (pokeaman['Type 1']=='Fire').astype(int)\n",
    "linear_model_specification_formula = \\\n",
    "'str8fyre ~ Attack*Legendary + Defense*I(Q(\"Type 2\")==\"None\") + C(Generation)'\n",
    "log_reg_fit = smf.logit(linear_model_specification_formula, data=pokeaman).fit()\n",
    "log_reg_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016496c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (4249915974.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    url = \"C:\\Users\\Enzo\\Downloads\\CSCS_data_anon.csv\"\u001b[0m\n\u001b[0m                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Load the dataset\n",
    "url = \"C:\\Users\\Enzo\\Downloads\\CSCS_data_anon.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Handle any missing data if necessary, for example by filling with means or dropping rows.\n",
    "data = data.fillna(data.mean())  # Or use other imputation strategies as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7572534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regression formula\n",
    "formula = '''\n",
    "    WELLNESS_life_satisfaction ~ DEMO_age * CONNECTION_activities_text_or_messaged_p3m \n",
    "    + DEMO_gender + CONNECTION_activities_video_chat_p3m + CONNECTION_activities_visited_friends_p3m\n",
    "    + COVID_vaccinated + WELLNESS_malach_pines_burnout_measure_tired\n",
    "'''\n",
    "# Example formula only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e91d2245",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m smf\u001b[38;5;241m.\u001b[39mols(formula, data\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m)\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Display the model summary\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model = smf.ols(formula, data=data).fit()\n",
    "\n",
    "# Display the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c45f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the formula to reflect binary categories\n",
    "formula_binary = '''\n",
    "    WELLNESS_life_satisfaction ~ C(DEMO_age_category) * C(CONNECTION_activities_text_or_messaged_high_low) \n",
    "    + DEMO_gender + CONNECTION_activities_video_chat_p3m + CONNECTION_activities_visited_friends_p3m\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e0812",
   "metadata": {},
   "source": [
    "# Question 4.\n",
    "\n",
    "This apparent contradiction arises because of the distinction between *statistical significance* of the individual coefficients and the *overall fit* or explanatory power of the model.\n",
    "\n",
    "1. **Low R-squared (Overall Fit)**:\n",
    "   - The statement \"the model only explains 17.6% of the variability in the data\" refers to the R-squared value, a measure of how well the model captures the variability in the response variable. An R-squared of 17.6% indicates that the model only explains a small portion of the total variability in the data. This implies that either the model is missing important predictors or that the outcome is inherently noisy or influenced by factors not included in the model.\n",
    "\n",
    "2. **Significance of Individual Coefficients**:\n",
    "   - The fact that \"many of the coefficients are larger than 10 while having strong or very strong evidence against the null hypothesis of 'no effect'\" indicates that these predictors are statistically significant. Statistical significance tests assess whether each predictor has an effect on the outcome, typically using p-values. When p-values are small, we reject the null hypothesis and conclude that the predictors are likely to have non-zero effects.\n",
    "   - Large coefficients with low p-values suggest that these predictors have a statistically detectable effect on the outcome, even though they may only explain a small amount of the total variation.\n",
    "\n",
    "3. **Interpretation**:\n",
    "   - In this case, it’s possible that the model includes predictors that do have significant, measurable effects on the response variable, but collectively, they only explain a small fraction of its total variation. This can happen if the data is complex, with multiple unmeasured variables that contribute to the variability in the outcome. Alternatively, the relationship between the predictors and the outcome could be weak or nonlinear in ways that the model does not capture well.\n",
    "\n",
    "In summary, the low R-squared reflects the model's limited ability to explain overall variability, while the significant coefficients indicate that some predictors still have meaningful, measurable effects on the outcome—even if they don't account for a large portion of its total variation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38958e51",
   "metadata": {},
   "source": [
    "# ChatBot Summary:\n",
    "\n",
    "Here is a summary of our exchanges:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Explaining Simple vs. Multiple Linear Regression:**\n",
    "   - **Simple Linear Regression** involves predicting an outcome using one predictor, while **Multiple Linear Regression** involves multiple predictors. The benefit of the latter is that it accounts for more factors and can explain the outcome better by incorporating more information.\n",
    "   - **Continuous vs. Indicator Variables in Regression**: Continuous variables represent numeric values, while indicator (or binary) variables represent categories. Including indicator variables in regression models allows you to capture the effect of categorical data.\n",
    "   - **Interaction Terms**: Adding interaction terms in a regression model allows for the effect of one predictor to change based on the level of another predictor, improving the model’s ability to represent complex relationships between predictors and the outcome.\n",
    "   - **Impact of Categorical Predictors**: When predictor variables are binary (e.g., \"high\" or \"low\" advertising budgets), the model coefficients will represent the change in the outcome relative to the baseline (low category), adjusting for any interactions between the variables.\n",
    "\n",
    "### 2. **Explaining Variables and Interactions in a Scenario:**\n",
    "   - For a company analyzing the effectiveness of TV and online advertising, **sales** is the outcome variable, and the predictors are the TV and online advertising budgets.\n",
    "   - Interaction terms are crucial because the effectiveness of each advertising type may depend on the other. A model with interaction terms would capture the combined effects of advertising budgets, whereas a model without interaction assumes their effects are independent.\n",
    "   - **Predictions**: A model with interaction will provide predictions where the effect of TV advertising on sales may change depending on the level of online advertising (and vice versa).\n",
    "   - **Binary Variables**: When budgets are categorized as \"high\" or \"low,\" the model changes to use indicator (binary) variables, and predictions will depend on whether each type of ad is high or low, along with potential interactions between these indicators.\n",
    "\n",
    "### 3. **Using `smf` to Fit Multiple Linear Regression Models:**\n",
    "   - A regression formula is defined using the dataset from the **Canadian Social Connection Survey** to predict **life satisfaction** using various predictors such as **age**, **gender**, and **social connection activities**.\n",
    "   - The model is fitted using `smf.ols()` to examine how predictors (like age and social activities) influence life satisfaction. Interaction terms are included to explore more complex relationships, such as the interaction between age and messaging frequency.\n",
    "   - The model summary is then displayed to evaluate the significance of the coefficients and their effects on life satisfaction.\n",
    "\n",
    "### 4. **Explaining the Contradiction Between Model Fit and Coefficient Significance:**\n",
    "   - The apparent contradiction arises because the **R-squared value** (17.6%) indicates that the model explains a small portion of the variability in the outcome, while **significant coefficients** with large magnitudes suggest that individual predictors have substantial and statistically significant effects.\n",
    "   - This situation occurs when the predictors are related to the outcome in specific, consistent ways, but many other unobserved factors contribute to unexplained variability. The significant coefficients show real effects, but the model overall doesn’t explain much of the total variance in the outcome.\n",
    "\n",
    "---\n",
    "\n",
    "This summary captures the key points of our discussions and can be submitted as part of your homework assignment. Let me know if you'd like any adjustments or additional details!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf3d06",
   "metadata": {},
   "source": [
    "# Question 5.\n",
    "\n",
    "This code appears to explore linear regression modeling on a dataset called `pokeaman`, which seems to include attributes for Pokémon, such as \"HP,\" \"Attack,\" \"Defense,\" \"Speed,\" etc. \n",
    "\n",
    "The cells' purpose and results:\n",
    "\n",
    "### Cell 1\n",
    "```python\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train\n",
    "```\n",
    "**Explanation:**\n",
    "- Imports necessary libraries and defines a train-test split for the dataset `pokeaman`.\n",
    "- Fills any missing values in the \"Type 2\" column with the string \"None\".\n",
    "- Uses a random seed for reproducibility and splits the data into a 50-50 train-test set (`pokeaman_train` and `pokeaman_test`).\n",
    "\n",
    "This step prepares the data for modeling and ensures that the model sees a balanced sample.\n",
    "\n",
    "### Cell 2\n",
    "```python\n",
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()\n",
    "```\n",
    "**Explanation:**\n",
    "- Builds a simple linear regression model (`model_spec3`) with \"HP\" as the dependent variable and \"Attack\" and \"Defense\" as predictors.\n",
    "- Fits the model to the training data (`pokeaman_train`) and prints the summary, which includes statistics like coefficients, p-values, and R-squared.\n",
    "\n",
    "The `summary()` output provides insights into how well \"Attack\" and \"Defense\" explain \"HP.\" The R-squared value will indicate the proportion of variance in \"HP\" that these predictors account for.\n",
    "\n",
    "### Cell 3\n",
    "```python\n",
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model3)[0,1]**2)\n",
    "```\n",
    "**Explanation:**\n",
    "- Predicts `HP` values for the test set using `model3_fit` and calculates two R-squared values:\n",
    "  - **In-sample R-squared**: The R-squared value from training, which shows the model's performance on the training data.\n",
    "  - **Out-of-sample R-squared**: The squared correlation between actual and predicted `HP` values on the test set, reflecting model performance on unseen data.\n",
    "\n",
    "This step shows how well `model3_fit` generalizes, with a comparison between in-sample and out-of-sample R-squared values.\n",
    "\n",
    "### Cell 4\n",
    "```python\n",
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# Avoid complex interactions that may slow down computation or crash\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()\n",
    "```\n",
    "**Explanation:**\n",
    "- Defines a more complex linear regression model (`model4_spec`) with interactions between multiple features: \"Attack,\" \"Defense,\" \"Speed,\" \"Legendary\" status, and \"Sp. Def\" and \"Sp. Atk\".\n",
    "- This model potentially captures more intricate relationships between these variables and \"HP\".\n",
    "\n",
    "The summary output will show if this more complex model offers significant improvements over `model3_fit`.\n",
    "\n",
    "### Cell 5\n",
    "```python\n",
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model4)[0,1]**2)\n",
    "```\n",
    "**Explanation:**\n",
    "- Similar to Cell 3, this code evaluates the predictive power of the more complex model (`model4_fit`) by computing both in-sample and out-of-sample R-squared values.\n",
    "- This comparison helps determine if the added complexity improved predictive accuracy on the test set.\n",
    "\n",
    "**Summary:**\n",
    "These five cells illustrate the progression from a simple to a complex regression model, with both in-sample and out-of-sample R-squared values showing how well each model generalizes. This setup helps understand the trade-offs between model simplicity and predictive performance, highlighting the importance of balancing model complexity to avoid overfitting while maximizing generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87db47dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519894\n",
      "'Out of sample' R-squared: 0.21208501873920738\n",
      "'In sample' R-squared:     0.46709442115833855\n",
      "'Out of sample' R-squared: 0.002485342598992873\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train,pokeaman_test = \\\n",
    "  train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train\n",
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', \n",
    "                      data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()\n",
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model3)[0,1]**2)\n",
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()\n",
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model4)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa406f1d",
   "metadata": {},
   "source": [
    "# Question 6.\n",
    "\n",
    "### Explanation of Model4 and Its Design Matrix\n",
    "\n",
    "In **Cell 4**, the `model4_linear_form` is specified as a formula that defines how the outcome variable (HP) is predicted by a set of predictors. The interaction terms, such as `Attack * Defense * Speed * Legendary`, create new predictor variables by combining these features in various ways. For example:\n",
    "- `Attack * Defense` produces an interaction term between Attack and Defense.\n",
    "- `Attack * Defense * Speed` adds a three-way interaction between Attack, Defense, and Speed.\n",
    "- The terms like `Q(\"Sp. Def\")` and `Q(\"Sp. Atk\")` refer to specific handling of categorical variables or potentially transformed columns.\n",
    "\n",
    "These interactions create new columns in the **design matrix** (`model4_spec.exog`), where each column represents a predictor or interaction. The design matrix is essentially a collection of all the independent variables used to predict the outcome. Each row corresponds to a data point, and each column is a specific variable (or interaction) that influences the predicted outcome. The shape of `model4_spec.exog` tells us how many predictors (features) and observations the model has.\n",
    "\n",
    "### Multicollinearity in the Design Matrix\n",
    "\n",
    "**Multicollinearity** occurs when two or more predictors in the design matrix are highly correlated. This can happen when:\n",
    "- Interaction terms involve predictors that are already correlated with each other (e.g., Attack and Defense might already be related, and their interaction term might introduce redundancy).\n",
    "- Some predictors are strongly related to each other, leading to difficulty in estimating their individual effects on the outcome.\n",
    "\n",
    "In the case of `model4_spec.exog`, the correlation matrix (`np.corrcoef(model4_spec.exog)`) would show high correlations between certain predictors, especially those derived from interactions. This **multicollinearity** makes it difficult for the regression model to reliably separate the unique contribution of each predictor to the outcome.\n",
    "\n",
    "As a result, the model struggles to generalize well to new (out-of-sample) data because the coefficients might become **unstable**. High multicollinearity makes the regression coefficients very sensitive to small changes in the data, leading to large variations in the model's predictions for new data points.\n",
    "\n",
    "### Impact on Model Performance and Condition Number\n",
    "\n",
    "The **condition number** is a diagnostic that reflects the sensitivity of the model's coefficients to multicollinearity. A high condition number indicates that the design matrix is ill-conditioned, meaning that the matrix is close to being singular (non-invertible), which is a sign of severe multicollinearity. In the case of `model4`, the **condition number** before centering and scaling was `343.0`, and even after centering and scaling, it remained extremely high (`2,250,000,000,000,000`), suggesting that multicollinearity persists.\n",
    "\n",
    "This high condition number contributes to the **poor out-of-sample generalization**. The model may perform well on the training data but fail to predict new data effectively because the unstable coefficients result in predictions that do not generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbdb7a4",
   "metadata": {},
   "source": [
    "# Question 7.\n",
    "\n",
    "The development of the models from `model3_fit` to `model7_fit` illustrates a gradual progression of adding complexity, refining predictors, and exploring interactions and transformations to improve prediction accuracy. Here's a breakdown of the rationale and principles behind each extension:\n",
    "\n",
    "### From `model3_fit` to `model5_linear_form`\n",
    "- **Rationale**: `model3_fit` was a simple model with just \"Attack\" and \"Defense\" as predictors for \"HP.\" `model5_linear_form` extends this by adding more predictors like \"Speed,\" \"Legendary,\" and categorical variables such as \"Type 1,\" \"Type 2,\" and \"Generation.\"\n",
    "- **Principle**: The goal is to incorporate additional features to better capture the variability in \"HP\" by using domain knowledge of Pokémon attributes (e.g., speed, type, generation). The inclusion of categorical variables using `C()` enables the model to account for the different levels within these categories, thus improving the model’s ability to explain the variance in \"HP.\"\n",
    "\n",
    "### From `model5_linear_form` to `model6_linear_form`\n",
    "- **Rationale**: `model6_linear_form` simplifies `model5_linear_form` by removing some predictors that might not contribute significantly to the model (e.g., \"Defense\"). It retains the key predictors like \"Attack,\" \"Speed,\" and special attributes like \"Sp. Def\" and \"Sp. Atk.\" Additionally, significant indicator variables from `model5_fit` (such as specific \"Type 1\" values and \"Generation\" values) are added to account for the effects of these categories on \"HP.\"\n",
    "- **Principle**: The rationale here is to focus the model on the most significant predictors identified in the previous model, while keeping indicators that highlight important categorical distinctions (e.g., specific Pokémon types and generations). This simplification helps avoid overfitting and improves interpretability while maintaining the model’s predictive power.\n",
    "\n",
    "### From `model6_linear_form` to `model7_linear_form`\n",
    "- **Rationale**: `model7_linear_form` further extends `model6_linear_form` by incorporating interaction terms (e.g., `Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")`). The interactions are designed to capture more complex relationships between the predictors, recognizing that the effect of one predictor (e.g., \"Attack\") might depend on the values of others (e.g., \"Speed\" and \"Sp. Def\").\n",
    "- **Principle**: The inclusion of interaction terms acknowledges that certain features may not independently influence \"HP\" but rather work together in a more complex way. By adding these interactions, the model can potentially uncover hidden relationships that improve its predictive performance, especially for more nuanced or non-linear effects.\n",
    "\n",
    "### From `model7_linear_form` to `model7_linear_form_CS`\n",
    "- **Rationale**: `model7_linear_form_CS` is an extension where the predictors are **centered and scaled** using `scale(center())`. This transformation normalizes the variables, making them have zero mean and unit variance, which helps mitigate issues like multicollinearity and improves numerical stability. Centering and scaling are especially useful when dealing with interaction terms, as they prevent one predictor from disproportionately affecting the model due to differences in scale.\n",
    "- **Principle**: The rationale behind centering and scaling is to improve the model's stability and to make sure that the coefficients are comparable in magnitude, especially when interaction terms are involved. This is a common technique to address multicollinearity and ensure that the model is numerically well-conditioned (evidenced by the significant reduction in the condition number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e10ad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.39050543408631777\n",
      "'Out of sample' R-squared: 0.2928211708652593\n",
      "'In sample' R-squared:     0.3278619119714917\n",
      "'Out of sample' R-squared: 0.3201730457445605\n",
      "'In sample' R-squared:     0.39896705495122187\n",
      "'Out of sample' R-squared: 0.29455630423884327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>268.963</td> <th>  Durbin-Watson:     </th> <td>   2.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4069.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.632</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>17.713</td>  <th>  Cond. No.          </th> <td>1.44e+09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 268.963 & \\textbf{  Durbin-Watson:     } &    2.180  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4069.702  \\\\\n",
       "\\textbf{Skew:}          &   2.632 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  17.713 & \\textbf{  Cond. No.          } & 1.44e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model5_linear_form = 'HP ~ Attack + Defense + Speed + Legendary'\n",
    "model5_linear_form += ' + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "model5_linear_form += ' + C(Generation) + C(Q(\"Type 1\")) + C(Q(\"Type 2\"))'\n",
    "\n",
    "model5_spec = smf.ols(formula=model5_linear_form, data=pokeaman_train)\n",
    "model5_fit = model5_spec.fit()\n",
    "model5_fit.summary()\n",
    "yhat_model5 = model5_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model5_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model5)[0,1]**2)\n",
    "# Here's something a little more reasonable...\n",
    "model6_linear_form = 'HP ~ Attack + Speed + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "# And here we'll add the significant indicators from the previous model\n",
    "# https://chatgpt.com/share/81ab88df-4f07-49f9-a44a-de0cfd89c67c\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model6_linear_form += ' + I(Generation==2)'\n",
    "model6_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model6_spec = smf.ols(formula=model6_linear_form, data=pokeaman_train)\n",
    "model6_fit = model6_spec.fit()\n",
    "model6_fit.summary()\n",
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2)\n",
    "# And here's a slight change that seems to perhaps improve prediction...\n",
    "model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form += ' + I(Generation==2)'\n",
    "model7_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model7_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "model7_fit = model7_spec.fit()\n",
    "model7_fit.summary()\n",
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2)\n",
    "# And here's a slight change that seems to perhas improve prediction...\n",
    "model7_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Speed))'\n",
    "model7_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# We DO NOT center and scale indicator variables\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form_CS += ' + I(Generation==2)'\n",
    "model7_linear_form_CS += ' + I(Generation==5)'\n",
    "\n",
    "model7_CS_spec = smf.ols(formula=model7_linear_form_CS, data=pokeaman_train)\n",
    "model7_CS_fit = model7_CS_spec.fit()\n",
    "model7_CS_fit.summary().tables[-1] \n",
    "# \"Cond. No.\" is NOW 15.4 due to centering and scaling\n",
    "# \"Cond. No.\" WAS 2,340,000,000 WITHOUT to centering and scaling\n",
    "model7_fit.summary().tables[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd677a",
   "metadata": {},
   "source": [
    "# Question 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "460a3c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "In Sample Performance (Rsquared)=%{x}<br>Out of Sample Performance (Rsquared)=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.1726254431950872,
          0.20102501755106528,
          0.21405036155097457,
          0.13956095241386546,
          0.13638214948229943,
          0.20478364176917163,
          0.14531708061923176,
          0.20394105436253018,
          0.13872191418449598,
          0.23564742882191037,
          0.23915202728912432,
          0.16121506759025672,
          0.1335669338635932,
          0.18698867997960233,
          0.21934122995205263,
          0.28376343932099723,
          0.1604311145470212,
          0.1849359585390956,
          0.17698409175217444,
          0.1696215416627458,
          0.22985251411213703,
          0.258163932654612,
          0.3243661956219418,
          0.2830230686974716,
          0.1515414305870626,
          0.11280846968418046,
          0.1831310226552828,
          0.16493136182473778,
          0.32126533470301777,
          0.15123632261926234,
          0.15867030129632775,
          0.1659296494714223,
          0.15771932925757237,
          0.27898851428586,
          0.1715097852076618,
          0.1798138060566129,
          0.20574040424116247,
          0.20095604652357957,
          0.13561392954613705,
          0.11666064188097125,
          0.2309890753475261,
          0.1738398201863819,
          0.16687154357528633,
          0.1571616668716237,
          0.13988631895849968,
          0.24089183497735156,
          0.17185746786498024,
          0.12255833844181607,
          0.19490873401239428,
          0.1612857852121703,
          0.11583033535211973,
          0.33646137685696054,
          0.1715554876146146,
          0.1403793845056096,
          0.20178262019368753,
          0.182627081951783,
          0.1845371106470105,
          0.12499259613336278,
          0.2463959450123444,
          0.17884385585246465,
          0.18088814768599237,
          0.15469539266380905,
          0.26547615446041195,
          0.22498078902104168,
          0.18424234483264879,
          0.17939208232723436,
          0.11573930768868335,
          0.268365429168006,
          0.2268118683796856,
          0.11880838298214291,
          0.27825548660106725,
          0.1745071794837736,
          0.21787717686783514,
          0.12985920534769801,
          0.18826426077162206,
          0.20627845866683658,
          0.2445459134581882,
          0.1407555679431568,
          0.29879893729749885,
          0.1997417067903572,
          0.14347849152182557,
          0.25314786077366047,
          0.22788980641887602,
          0.12149394657027857,
          0.22929590002592581,
          0.22466194246031534,
          0.17272832718903441,
          0.18590781609026796,
          0.16151042445006103,
          0.17559434708588884,
          0.18417444081777867,
          0.20831753069851988,
          0.22336316705147163,
          0.1961425453812753,
          0.1992841046191125,
          0.16078136348546568,
          0.216211325341513,
          0.19223029205774111,
          0.10262931744181225,
          0.12681558082274125
         ],
         "xaxis": "x",
         "y": [
          0.19158533176005327,
          0.16356399942043048,
          0.1522834865411352,
          0.23662854385149162,
          0.2298295690609623,
          0.1623528635529275,
          0.21973814811485443,
          0.1630632540936025,
          0.23171704596943052,
          0.14205245237629732,
          0.1342379581009219,
          0.2068441672178092,
          0.23873974976734483,
          0.17624624289053326,
          0.15352921400067981,
          0.1144991809409339,
          0.18577888950561014,
          0.17796877220552523,
          0.17781489616983295,
          0.1963892928065535,
          0.14653401528063442,
          0.12638167520385377,
          0.1012395288754547,
          0.11927011529959268,
          0.22934982246521785,
          0.28199679909436615,
          0.16587112603089033,
          0.19729439413365493,
          0.09696577863792158,
          0.21572608067488785,
          0.20642439547603325,
          0.19899490498976466,
          0.20559929895030843,
          0.11533054823591629,
          0.1964609791851324,
          0.1865833411111896,
          0.1585461894639747,
          0.1660393294825178,
          0.24546082804012243,
          0.2641657958110762,
          0.13931526098994465,
          0.19145342040419866,
          0.18916781008899952,
          0.21560911415641337,
          0.21612442345110122,
          0.13497044075795825,
          0.18691757439281576,
          0.2723776070137962,
          0.16825028309157838,
          0.20503387943769022,
          0.28120317849240406,
          0.09039274951664461,
          0.1959469808005202,
          0.23061964595928983,
          0.1650911290012516,
          0.18701044714395898,
          0.1796260843422289,
          0.26770300812390374,
          0.12121864028033288,
          0.18764728079138535,
          0.1736300109491942,
          0.20890531351499084,
          0.12164923940116759,
          0.14193254041093775,
          0.17562786994313767,
          0.18359670475064188,
          0.2862252671465983,
          0.12014360702467433,
          0.14671166822158654,
          0.27187568405821955,
          0.11744316223140652,
          0.19210456606557225,
          0.15062859623247565,
          0.23568941893465437,
          0.17606505091429375,
          0.1617880402330615,
          0.13046232081604306,
          0.2385024013398722,
          0.1108272584806573,
          0.1663242673553989,
          0.23252912733441675,
          0.12665236013726333,
          0.14794330005295403,
          0.26643317473131933,
          0.1457993446223853,
          0.1411049201785041,
          0.19338663171947681,
          0.17781663026841318,
          0.20916271034548403,
          0.1880948059722003,
          0.1789130540643561,
          0.15788130931297112,
          0.14701418594318874,
          0.16677722711678034,
          0.16495261885909226,
          0.20284360252399783,
          0.15271524712621332,
          0.17244850479230053,
          0.2864023033627878,
          0.2557784915456163
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "shape": "linear"
         },
         "name": "y=x",
         "type": "scatter",
         "x": [
          0,
          1
         ],
         "y": [
          0,
          1
         ]
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "In-sample vs Out-of-sample R-squared for Multiple Model Runs"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "In Sample Performance (Rsquared)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Out of Sample Performance (Rsquared)"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"5e4f07b2-fbb6-4cf1-a0cb-dd7176fe9135\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5e4f07b2-fbb6-4cf1-a0cb-dd7176fe9135\")) {                    Plotly.newPlot(                        \"5e4f07b2-fbb6-4cf1-a0cb-dd7176fe9135\",                        [{\"hovertemplate\":\"In Sample Performance (Rsquared)=%{x}\\u003cbr\\u003eOut of Sample Performance (Rsquared)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.1726254431950872,0.20102501755106528,0.21405036155097457,0.13956095241386546,0.13638214948229943,0.20478364176917163,0.14531708061923176,0.20394105436253018,0.13872191418449598,0.23564742882191037,0.23915202728912432,0.16121506759025672,0.1335669338635932,0.18698867997960233,0.21934122995205263,0.28376343932099723,0.1604311145470212,0.1849359585390956,0.17698409175217444,0.1696215416627458,0.22985251411213703,0.258163932654612,0.3243661956219418,0.2830230686974716,0.1515414305870626,0.11280846968418046,0.1831310226552828,0.16493136182473778,0.32126533470301777,0.15123632261926234,0.15867030129632775,0.1659296494714223,0.15771932925757237,0.27898851428586,0.1715097852076618,0.1798138060566129,0.20574040424116247,0.20095604652357957,0.13561392954613705,0.11666064188097125,0.2309890753475261,0.1738398201863819,0.16687154357528633,0.1571616668716237,0.13988631895849968,0.24089183497735156,0.17185746786498024,0.12255833844181607,0.19490873401239428,0.1612857852121703,0.11583033535211973,0.33646137685696054,0.1715554876146146,0.1403793845056096,0.20178262019368753,0.182627081951783,0.1845371106470105,0.12499259613336278,0.2463959450123444,0.17884385585246465,0.18088814768599237,0.15469539266380905,0.26547615446041195,0.22498078902104168,0.18424234483264879,0.17939208232723436,0.11573930768868335,0.268365429168006,0.2268118683796856,0.11880838298214291,0.27825548660106725,0.1745071794837736,0.21787717686783514,0.12985920534769801,0.18826426077162206,0.20627845866683658,0.2445459134581882,0.1407555679431568,0.29879893729749885,0.1997417067903572,0.14347849152182557,0.25314786077366047,0.22788980641887602,0.12149394657027857,0.22929590002592581,0.22466194246031534,0.17272832718903441,0.18590781609026796,0.16151042445006103,0.17559434708588884,0.18417444081777867,0.20831753069851988,0.22336316705147163,0.1961425453812753,0.1992841046191125,0.16078136348546568,0.216211325341513,0.19223029205774111,0.10262931744181225,0.12681558082274125],\"xaxis\":\"x\",\"y\":[0.19158533176005327,0.16356399942043048,0.1522834865411352,0.23662854385149162,0.2298295690609623,0.1623528635529275,0.21973814811485443,0.1630632540936025,0.23171704596943052,0.14205245237629732,0.1342379581009219,0.2068441672178092,0.23873974976734483,0.17624624289053326,0.15352921400067981,0.1144991809409339,0.18577888950561014,0.17796877220552523,0.17781489616983295,0.1963892928065535,0.14653401528063442,0.12638167520385377,0.1012395288754547,0.11927011529959268,0.22934982246521785,0.28199679909436615,0.16587112603089033,0.19729439413365493,0.09696577863792158,0.21572608067488785,0.20642439547603325,0.19899490498976466,0.20559929895030843,0.11533054823591629,0.1964609791851324,0.1865833411111896,0.1585461894639747,0.1660393294825178,0.24546082804012243,0.2641657958110762,0.13931526098994465,0.19145342040419866,0.18916781008899952,0.21560911415641337,0.21612442345110122,0.13497044075795825,0.18691757439281576,0.2723776070137962,0.16825028309157838,0.20503387943769022,0.28120317849240406,0.09039274951664461,0.1959469808005202,0.23061964595928983,0.1650911290012516,0.18701044714395898,0.1796260843422289,0.26770300812390374,0.12121864028033288,0.18764728079138535,0.1736300109491942,0.20890531351499084,0.12164923940116759,0.14193254041093775,0.17562786994313767,0.18359670475064188,0.2862252671465983,0.12014360702467433,0.14671166822158654,0.27187568405821955,0.11744316223140652,0.19210456606557225,0.15062859623247565,0.23568941893465437,0.17606505091429375,0.1617880402330615,0.13046232081604306,0.2385024013398722,0.1108272584806573,0.1663242673553989,0.23252912733441675,0.12665236013726333,0.14794330005295403,0.26643317473131933,0.1457993446223853,0.1411049201785041,0.19338663171947681,0.17781663026841318,0.20916271034548403,0.1880948059722003,0.1789130540643561,0.15788130931297112,0.14701418594318874,0.16677722711678034,0.16495261885909226,0.20284360252399783,0.15271524712621332,0.17244850479230053,0.2864023033627878,0.2557784915456163],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"shape\":\"linear\"},\"name\":\"y=x\",\"x\":[0,1],\"y\":[0,1],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"In Sample Performance (Rsquared)\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Out of Sample Performance (Rsquared)\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"In-sample vs Out-of-sample R-squared for Multiple Model Runs\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5e4f07b2-fbb6-4cf1-a0cb-dd7176fe9135');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Define the linear form specification for model3_fit\n",
    "linear_form = 'HP ~ Attack + Defense'\n",
    "\n",
    "# Number of repetitions for cross-validation\n",
    "reps = 100\n",
    "\n",
    "# Initialize arrays to collect R-squared values\n",
    "in_sample_Rsquared = np.array([0.0]*reps)\n",
    "out_of_sample_Rsquared = np.array([0.0]*reps)\n",
    "\n",
    "# Loop for multiple iterations to assess performance\n",
    "for i in range(reps):\n",
    "    # Perform the 50-50 train-test split without using np.random.seed(130) each time\n",
    "    pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=0.5)\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    final_model_fit = smf.ols(formula=linear_form, data=pokeaman_train).fit()\n",
    "    \n",
    "    # Collect in-sample R-squared (model fit on the training data)\n",
    "    in_sample_Rsquared[i] = final_model_fit.rsquared\n",
    "    \n",
    "    # Collect out-of-sample R-squared (model prediction on the test data)\n",
    "    y_test = pokeaman_test.HP\n",
    "    yhat_test = final_model_fit.predict(pokeaman_test)\n",
    "    out_of_sample_Rsquared[i] = np.corrcoef(y_test, yhat_test)[0, 1] ** 2\n",
    "\n",
    "# Store results in a DataFrame\n",
    "df = pd.DataFrame({\"In Sample Performance (Rsquared)\": in_sample_Rsquared,\n",
    "                   \"Out of Sample Performance (Rsquared)\": out_of_sample_Rsquared})\n",
    "\n",
    "# Visualize the results using a scatter plot\n",
    "fig = px.scatter(df, x=\"In Sample Performance (Rsquared)\", \n",
    "                     y=\"Out of Sample Performance (Rsquared)\",\n",
    "                     title=\"In-sample vs Out-of-sample R-squared for Multiple Model Runs\")\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], name=\"y=x\", line_shape='linear'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af80985",
   "metadata": {},
   "source": [
    "### Explanation of Results:\n",
    "\n",
    "- **In-Sample R-squared**: This metric measures how well the model fits the training data. Higher values indicate better model fit on the training data.\n",
    "  \n",
    "- **Out-of-Sample R-squared**: This metric measures how well the model generalizes to new data. It is calculated using the test data, and higher values suggest better generalization.\n",
    "\n",
    "- **Scatter Plot**: The scatter plot illustrates the variability of in-sample and out-of-sample R-squared values across different iterations. A perfect model would produce points along the diagonal line (`y=x`), where the in-sample and out-of-sample R-squared values are identical. However, in practice, we typically observe a range of values, with some models overfitting (high in-sample R-squared and low out-of-sample R-squared) and others performing well on both in-sample and out-of-sample data.\n",
    "\n",
    "### Purpose of the Demonstration:\n",
    "\n",
    "This demonstration serves to visualize and understand the **variability in model performance** when applying the same model specification (e.g., `model3_fit`) across multiple train-test splits. It shows how the model might behave with different subsets of data and emphasizes the importance of **out-of-sample performance** in assessing how well the model will generalize to unseen data. The plot highlights the need to avoid overfitting, where the model may fit the training data well but fail to perform on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98e5ed",
   "metadata": {},
   "source": [
    "# Question 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "048c7914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.39896705495122187 (original)\n",
      "'Out of sample' R-squared: 0.008741299280319925 (original)\n",
      "'In sample' R-squared:     0.5726118179916575 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.11151363354803218 (gen1_predict_future)\n",
      "'In sample' R-squared:     0.39896705495122187 (original)\n",
      "'Out of sample' R-squared: 0.008741299280319925 (original)\n",
      "'In sample' R-squared:     0.3904756578094535 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.23394915464343125 (gen1to5_predict_future)\n",
      "'In sample' R-squared:     0.3278619119714917 (original)\n",
      "'Out of sample' R-squared: 0.012706187160367099 (original)\n",
      "'In sample' R-squared:     0.4433880517727282 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.1932858534276128 (gen1_predict_future)\n",
      "'In sample' R-squared:     0.3278619119714917 (original)\n",
      "'Out of sample' R-squared: 0.012706187160367099 (original)\n",
      "'In sample' R-squared:     0.33517279824114776 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.26262690178799936 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model7_gen1_predict_future_fit = model7_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model7_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")\n",
    "model7_gen1to5_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model7_gen1to5_predict_future_fit = model7_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model7_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")\n",
    "model6_gen1_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model6_gen1_predict_future_fit = model6_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model6_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")\n",
    "model6_gen1to5_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model6_gen1to5_predict_future_fit = model6_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model6_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aafe00",
   "metadata": {},
   "source": [
    "The illustration discusses the trade-offs between two models, **model6_fit** and **model7_fit**, in terms of their complexity, performance, and generalizability. The key points in the explanation emphasize how the complexity of **model7_fit** may introduce overfitting issues, even though it performs better on test data (\"out-of-sample\" performance) compared to **model6_fit**. Here's a breakdown:\n",
    "\n",
    "1. **Complexity and Parsimony**: \n",
    "   - **model7_fit** is more complex than **model6_fit** because it includes more interactions, such as the four-way interaction term `Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")`. While this may improve the model's performance on training data, it can also lead to overfitting. Overfitting happens when a model captures noise or idiosyncrasies in the training data that do not generalize well to new, unseen data.\n",
    "   - **model6_fit**, being simpler, has a clearer and more interpretable structure. It may not perform as well in the short term, but it is more likely to generalize better because it avoids capturing these spurious patterns in the data.\n",
    "\n",
    "2. **Interpretability vs. Performance**:\n",
    "   - The complexity of **model7_fit** makes it harder to interpret. For instance, understanding a four-way interaction term in conjunction with other lower-order interactions can be quite challenging. In contrast, **model6_fit**'s simpler structure is more interpretable and easier to understand.\n",
    "   - This trade-off between model performance and interpretability is crucial, especially when the performance difference between the two models is not dramatic. In some cases, a simpler, more interpretable model is preferred, even if its \"out-of-sample\" performance is slightly worse.\n",
    "\n",
    "3. **Generalizability**:\n",
    "   - The concern with **model7_fit**'s complexity is its potential for overfitting, which reduces its ability to generalize to new data. The model might detect patterns in the training set that are not present in the real world or new datasets.\n",
    "   - A simpler model, like **model6_fit**, might generalize better to future data, as shown in the sequential data predictions using \"Generations.\" This better generalizability is one reason why **model6_fit** could be preferred despite its slightly lower performance on test data.\n",
    "\n",
    "4. **Real-World Application**:\n",
    "   - The code illustrates how data might arrive sequentially (e.g., in \"Generations\"), and models should be tested on their ability to predict future data based on the current available data. **model7_fit**'s complexity can cause issues in these real-world scenarios, where data isn't idealized or static. The predictive performance of **model7_fit** declines when applied to future \"Generations,\" highlighting its overfitting tendencies.\n",
    "\n",
    "In conclusion, while **model7_fit** might perform better on current test data, its complexity and lack of interpretability, as well as its tendency to overfit, make **model6_fit** a safer and more robust choice in practice. This reinforces the idea that simplicity in modeling often leads to more consistent generalization, better interpretability, and fewer overfitting risks, which is crucial in real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d29eac",
   "metadata": {},
   "source": [
    "# ChatBot Summary:\n",
    "\n",
    "Here is a summary of our exchanges:\n",
    "\n",
    "---\n",
    "\n",
    "1. **Model Complexity and Interpretability**: We discussed the trade-off between two models, **model7_fit** and **model6_fit**, focusing on how the complexity of **model7_fit** leads to overfitting and challenges in interpretability. While **model7_fit** performs better in out-of-sample tests, **model6_fit** is simpler and more interpretable, with better generalizability.\n",
    "\n",
    "2. **Generalizability Concerns**: The increased complexity of **model7_fit** reduces its ability to generalize to new data, as demonstrated by sequential \"Generations\" data. In contrast, the simpler **model6_fit** shows more consistent performance and generalizability.\n",
    "\n",
    "3. **Real-World Application**: The discussion emphasized the importance of model simplicity and interpretability in real-world applications where data arrives sequentially, highlighting the risk of overfitting with more complex models.\n",
    "\n",
    "This summary captures the main points of our discussion on model selection and generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d3523d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
